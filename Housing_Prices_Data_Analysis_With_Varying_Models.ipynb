{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b387faa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn most situations, there is no way to determine the best number of hidden\\nunits without training several networks and estimating the generalization\\nerror of each. If you have too few hidden units, you will get high training\\nerror and high generalization error due to underfitting and high statistical\\nbias. If you have too many hidden units, you may get low training error but\\nstill have high generalization error due to overfitting and high variance.\\n\\nFor this notebook we will use a rule of thumb that has been cited in literature to start with, as our assumption\\nand expand use a heuristic approach to find the best size of our hidden layer\\nWe want to create a model to determine house prices\\n\\nWe will start with \\n   (Number of inputs + outputs) * (2/3) = amount of nodes \\n   \\nWe will then take 25% of this amount, then 50%, 75%, and 125% and test which model performs best with the amount of nodes\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In most situations, there is no way to determine the best number of hidden\n",
    "units without training several networks and estimating the generalization\n",
    "error of each. If you have too few hidden units, you will get high training\n",
    "error and high generalization error due to underfitting and high statistical\n",
    "bias. If you have too many hidden units, you may get low training error but\n",
    "still have high generalization error due to overfitting and high variance.\n",
    "\n",
    "For this notebook we will use a rule of thumb that has been cited in literature to start with, as our assumption\n",
    "and expand use a heuristic approach to find the best size of our hidden layer\n",
    "We want to create a model to determine house prices\n",
    "\n",
    "We will start with \n",
    "   (Number of inputs + outputs) * (2/3) = amount of nodes \n",
    "   \n",
    "We will then take 25% of this amount, then 50%, 75%, and 125% and test which model performs best with the amount of nodes\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd47fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c466b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data = pd.read_csv(\"kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb8523dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7237550310</td>\n",
       "      <td>20140512T000000</td>\n",
       "      <td>1225000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5420</td>\n",
       "      <td>101930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3890</td>\n",
       "      <td>1530</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.6561</td>\n",
       "      <td>-122.005</td>\n",
       "      <td>4760</td>\n",
       "      <td>101930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1321400060</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>257500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000   221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000   538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000   180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000   604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000   510000.0         3       2.00         1680   \n",
       "5  7237550310  20140512T000000  1225000.0         4       4.50         5420   \n",
       "6  1321400060  20140627T000000   257500.0         3       2.25         1715   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "5    101930     1.0           0     0  ...     11        3890           1530   \n",
       "6      6819     2.0           0     0  ...      7        1715              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "5      2001             0    98053  47.6561 -122.005           4760   \n",
       "6      1995             0    98003  47.3097 -122.327           2238   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "5      101930  \n",
       "6        6819  \n",
       "\n",
       "[7 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea9a0313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21613 non-null  int64  \n",
      " 1   date           21613 non-null  object \n",
      " 2   price          21613 non-null  float64\n",
      " 3   bedrooms       21613 non-null  int64  \n",
      " 4   bathrooms      21613 non-null  float64\n",
      " 5   sqft_living    21613 non-null  int64  \n",
      " 6   sqft_lot       21613 non-null  int64  \n",
      " 7   floors         21613 non-null  float64\n",
      " 8   waterfront     21613 non-null  int64  \n",
      " 9   view           21613 non-null  int64  \n",
      " 10  condition      21613 non-null  int64  \n",
      " 11  grade          21613 non-null  int64  \n",
      " 12  sqft_above     21613 non-null  int64  \n",
      " 13  sqft_basement  21613 non-null  int64  \n",
      " 14  yr_built       21613 non-null  int64  \n",
      " 15  yr_renovated   21613 non-null  int64  \n",
      " 16  zipcode        21613 non-null  int64  \n",
      " 17  lat            21613 non-null  float64\n",
      " 18  long           21613 non-null  float64\n",
      " 19  sqft_living15  21613 non-null  int64  \n",
      " 20  sqft_lot15     21613 non-null  int64  \n",
      "dtypes: float64(5), int64(15), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "house_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de310d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016762</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>-0.012258</td>\n",
       "      <td>-0.132109</td>\n",
       "      <td>0.018525</td>\n",
       "      <td>-0.002721</td>\n",
       "      <td>0.011592</td>\n",
       "      <td>-0.023783</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>-0.010842</td>\n",
       "      <td>-0.005151</td>\n",
       "      <td>0.021380</td>\n",
       "      <td>-0.016907</td>\n",
       "      <td>-0.008224</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>-0.002901</td>\n",
       "      <td>-0.138798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>-0.016762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.308350</td>\n",
       "      <td>0.525138</td>\n",
       "      <td>0.702035</td>\n",
       "      <td>0.089661</td>\n",
       "      <td>0.256794</td>\n",
       "      <td>0.266369</td>\n",
       "      <td>0.397293</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>0.667434</td>\n",
       "      <td>0.605567</td>\n",
       "      <td>0.323816</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>0.126434</td>\n",
       "      <td>-0.053203</td>\n",
       "      <td>0.307003</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>0.585379</td>\n",
       "      <td>0.082447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.308350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.515884</td>\n",
       "      <td>0.576671</td>\n",
       "      <td>0.031703</td>\n",
       "      <td>0.175429</td>\n",
       "      <td>-0.006582</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>0.028472</td>\n",
       "      <td>0.356967</td>\n",
       "      <td>0.477600</td>\n",
       "      <td>0.303093</td>\n",
       "      <td>0.154178</td>\n",
       "      <td>0.018841</td>\n",
       "      <td>-0.152668</td>\n",
       "      <td>-0.008931</td>\n",
       "      <td>0.129473</td>\n",
       "      <td>0.391638</td>\n",
       "      <td>0.029244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.525138</td>\n",
       "      <td>0.515884</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754665</td>\n",
       "      <td>0.087740</td>\n",
       "      <td>0.500653</td>\n",
       "      <td>0.063744</td>\n",
       "      <td>0.187737</td>\n",
       "      <td>-0.124982</td>\n",
       "      <td>0.664983</td>\n",
       "      <td>0.685342</td>\n",
       "      <td>0.283770</td>\n",
       "      <td>0.506019</td>\n",
       "      <td>0.050739</td>\n",
       "      <td>-0.203866</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>0.223042</td>\n",
       "      <td>0.568634</td>\n",
       "      <td>0.087175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living</th>\n",
       "      <td>-0.012258</td>\n",
       "      <td>0.702035</td>\n",
       "      <td>0.576671</td>\n",
       "      <td>0.754665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172826</td>\n",
       "      <td>0.353949</td>\n",
       "      <td>0.103818</td>\n",
       "      <td>0.284611</td>\n",
       "      <td>-0.058753</td>\n",
       "      <td>0.762704</td>\n",
       "      <td>0.876597</td>\n",
       "      <td>0.435043</td>\n",
       "      <td>0.318049</td>\n",
       "      <td>0.055363</td>\n",
       "      <td>-0.199430</td>\n",
       "      <td>0.052529</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.756420</td>\n",
       "      <td>0.183286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot</th>\n",
       "      <td>-0.132109</td>\n",
       "      <td>0.089661</td>\n",
       "      <td>0.031703</td>\n",
       "      <td>0.087740</td>\n",
       "      <td>0.172826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005201</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>0.074710</td>\n",
       "      <td>-0.008958</td>\n",
       "      <td>0.113621</td>\n",
       "      <td>0.183512</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.053080</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>-0.129574</td>\n",
       "      <td>-0.085683</td>\n",
       "      <td>0.229521</td>\n",
       "      <td>0.144608</td>\n",
       "      <td>0.718557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floors</th>\n",
       "      <td>0.018525</td>\n",
       "      <td>0.256794</td>\n",
       "      <td>0.175429</td>\n",
       "      <td>0.500653</td>\n",
       "      <td>0.353949</td>\n",
       "      <td>-0.005201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023698</td>\n",
       "      <td>0.029444</td>\n",
       "      <td>-0.263768</td>\n",
       "      <td>0.458183</td>\n",
       "      <td>0.523885</td>\n",
       "      <td>-0.245705</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>-0.059121</td>\n",
       "      <td>0.049614</td>\n",
       "      <td>0.125419</td>\n",
       "      <td>0.279885</td>\n",
       "      <td>-0.011269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterfront</th>\n",
       "      <td>-0.002721</td>\n",
       "      <td>0.266369</td>\n",
       "      <td>-0.006582</td>\n",
       "      <td>0.063744</td>\n",
       "      <td>0.103818</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>0.023698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401857</td>\n",
       "      <td>0.016653</td>\n",
       "      <td>0.082775</td>\n",
       "      <td>0.072075</td>\n",
       "      <td>0.080588</td>\n",
       "      <td>-0.026161</td>\n",
       "      <td>0.092885</td>\n",
       "      <td>0.030285</td>\n",
       "      <td>-0.014274</td>\n",
       "      <td>-0.041910</td>\n",
       "      <td>0.086463</td>\n",
       "      <td>0.030703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <td>0.011592</td>\n",
       "      <td>0.397293</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>0.187737</td>\n",
       "      <td>0.284611</td>\n",
       "      <td>0.074710</td>\n",
       "      <td>0.029444</td>\n",
       "      <td>0.401857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>0.251321</td>\n",
       "      <td>0.167649</td>\n",
       "      <td>0.276947</td>\n",
       "      <td>-0.053440</td>\n",
       "      <td>0.103917</td>\n",
       "      <td>0.084827</td>\n",
       "      <td>0.006157</td>\n",
       "      <td>-0.078400</td>\n",
       "      <td>0.280439</td>\n",
       "      <td>0.072575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <td>-0.023783</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>0.028472</td>\n",
       "      <td>-0.124982</td>\n",
       "      <td>-0.058753</td>\n",
       "      <td>-0.008958</td>\n",
       "      <td>-0.263768</td>\n",
       "      <td>0.016653</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.144674</td>\n",
       "      <td>-0.158214</td>\n",
       "      <td>0.174105</td>\n",
       "      <td>-0.361417</td>\n",
       "      <td>-0.060618</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>-0.014941</td>\n",
       "      <td>-0.106500</td>\n",
       "      <td>-0.092824</td>\n",
       "      <td>-0.003406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.667434</td>\n",
       "      <td>0.356967</td>\n",
       "      <td>0.664983</td>\n",
       "      <td>0.762704</td>\n",
       "      <td>0.113621</td>\n",
       "      <td>0.458183</td>\n",
       "      <td>0.082775</td>\n",
       "      <td>0.251321</td>\n",
       "      <td>-0.144674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.755923</td>\n",
       "      <td>0.168392</td>\n",
       "      <td>0.446963</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>-0.184862</td>\n",
       "      <td>0.114084</td>\n",
       "      <td>0.198372</td>\n",
       "      <td>0.713202</td>\n",
       "      <td>0.119248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_above</th>\n",
       "      <td>-0.010842</td>\n",
       "      <td>0.605567</td>\n",
       "      <td>0.477600</td>\n",
       "      <td>0.685342</td>\n",
       "      <td>0.876597</td>\n",
       "      <td>0.183512</td>\n",
       "      <td>0.523885</td>\n",
       "      <td>0.072075</td>\n",
       "      <td>0.167649</td>\n",
       "      <td>-0.158214</td>\n",
       "      <td>0.755923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.051943</td>\n",
       "      <td>0.423898</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>-0.261190</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>0.343803</td>\n",
       "      <td>0.731870</td>\n",
       "      <td>0.194050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_basement</th>\n",
       "      <td>-0.005151</td>\n",
       "      <td>0.323816</td>\n",
       "      <td>0.303093</td>\n",
       "      <td>0.283770</td>\n",
       "      <td>0.435043</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>-0.245705</td>\n",
       "      <td>0.080588</td>\n",
       "      <td>0.276947</td>\n",
       "      <td>0.174105</td>\n",
       "      <td>0.168392</td>\n",
       "      <td>-0.051943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.133124</td>\n",
       "      <td>0.071323</td>\n",
       "      <td>0.074845</td>\n",
       "      <td>0.110538</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>0.200355</td>\n",
       "      <td>0.017276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_built</th>\n",
       "      <td>0.021380</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>0.154178</td>\n",
       "      <td>0.506019</td>\n",
       "      <td>0.318049</td>\n",
       "      <td>0.053080</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>-0.026161</td>\n",
       "      <td>-0.053440</td>\n",
       "      <td>-0.361417</td>\n",
       "      <td>0.446963</td>\n",
       "      <td>0.423898</td>\n",
       "      <td>-0.133124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.224874</td>\n",
       "      <td>-0.346869</td>\n",
       "      <td>-0.148122</td>\n",
       "      <td>0.409356</td>\n",
       "      <td>0.326229</td>\n",
       "      <td>0.070958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yr_renovated</th>\n",
       "      <td>-0.016907</td>\n",
       "      <td>0.126434</td>\n",
       "      <td>0.018841</td>\n",
       "      <td>0.050739</td>\n",
       "      <td>0.055363</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.092885</td>\n",
       "      <td>0.103917</td>\n",
       "      <td>-0.060618</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>0.071323</td>\n",
       "      <td>-0.224874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064357</td>\n",
       "      <td>0.029398</td>\n",
       "      <td>-0.068372</td>\n",
       "      <td>-0.002673</td>\n",
       "      <td>0.007854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode</th>\n",
       "      <td>-0.008224</td>\n",
       "      <td>-0.053203</td>\n",
       "      <td>-0.152668</td>\n",
       "      <td>-0.203866</td>\n",
       "      <td>-0.199430</td>\n",
       "      <td>-0.129574</td>\n",
       "      <td>-0.059121</td>\n",
       "      <td>0.030285</td>\n",
       "      <td>0.084827</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>-0.184862</td>\n",
       "      <td>-0.261190</td>\n",
       "      <td>0.074845</td>\n",
       "      <td>-0.346869</td>\n",
       "      <td>0.064357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.267048</td>\n",
       "      <td>-0.564072</td>\n",
       "      <td>-0.279033</td>\n",
       "      <td>-0.147221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.307003</td>\n",
       "      <td>-0.008931</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>0.052529</td>\n",
       "      <td>-0.085683</td>\n",
       "      <td>0.049614</td>\n",
       "      <td>-0.014274</td>\n",
       "      <td>0.006157</td>\n",
       "      <td>-0.014941</td>\n",
       "      <td>0.114084</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>0.110538</td>\n",
       "      <td>-0.148122</td>\n",
       "      <td>0.029398</td>\n",
       "      <td>0.267048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.135512</td>\n",
       "      <td>0.048858</td>\n",
       "      <td>-0.086419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.021626</td>\n",
       "      <td>0.129473</td>\n",
       "      <td>0.223042</td>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.229521</td>\n",
       "      <td>0.125419</td>\n",
       "      <td>-0.041910</td>\n",
       "      <td>-0.078400</td>\n",
       "      <td>-0.106500</td>\n",
       "      <td>0.198372</td>\n",
       "      <td>0.343803</td>\n",
       "      <td>-0.144765</td>\n",
       "      <td>0.409356</td>\n",
       "      <td>-0.068372</td>\n",
       "      <td>-0.564072</td>\n",
       "      <td>-0.135512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334605</td>\n",
       "      <td>0.254451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_living15</th>\n",
       "      <td>-0.002901</td>\n",
       "      <td>0.585379</td>\n",
       "      <td>0.391638</td>\n",
       "      <td>0.568634</td>\n",
       "      <td>0.756420</td>\n",
       "      <td>0.144608</td>\n",
       "      <td>0.279885</td>\n",
       "      <td>0.086463</td>\n",
       "      <td>0.280439</td>\n",
       "      <td>-0.092824</td>\n",
       "      <td>0.713202</td>\n",
       "      <td>0.731870</td>\n",
       "      <td>0.200355</td>\n",
       "      <td>0.326229</td>\n",
       "      <td>-0.002673</td>\n",
       "      <td>-0.279033</td>\n",
       "      <td>0.048858</td>\n",
       "      <td>0.334605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.183192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqft_lot15</th>\n",
       "      <td>-0.138798</td>\n",
       "      <td>0.082447</td>\n",
       "      <td>0.029244</td>\n",
       "      <td>0.087175</td>\n",
       "      <td>0.183286</td>\n",
       "      <td>0.718557</td>\n",
       "      <td>-0.011269</td>\n",
       "      <td>0.030703</td>\n",
       "      <td>0.072575</td>\n",
       "      <td>-0.003406</td>\n",
       "      <td>0.119248</td>\n",
       "      <td>0.194050</td>\n",
       "      <td>0.017276</td>\n",
       "      <td>0.070958</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>-0.147221</td>\n",
       "      <td>-0.086419</td>\n",
       "      <td>0.254451</td>\n",
       "      <td>0.183192</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "id             1.000000 -0.016762  0.001286   0.005160    -0.012258 -0.132109   \n",
       "price         -0.016762  1.000000  0.308350   0.525138     0.702035  0.089661   \n",
       "bedrooms       0.001286  0.308350  1.000000   0.515884     0.576671  0.031703   \n",
       "bathrooms      0.005160  0.525138  0.515884   1.000000     0.754665  0.087740   \n",
       "sqft_living   -0.012258  0.702035  0.576671   0.754665     1.000000  0.172826   \n",
       "sqft_lot      -0.132109  0.089661  0.031703   0.087740     0.172826  1.000000   \n",
       "floors         0.018525  0.256794  0.175429   0.500653     0.353949 -0.005201   \n",
       "waterfront    -0.002721  0.266369 -0.006582   0.063744     0.103818  0.021604   \n",
       "view           0.011592  0.397293  0.079532   0.187737     0.284611  0.074710   \n",
       "condition     -0.023783  0.036362  0.028472  -0.124982    -0.058753 -0.008958   \n",
       "grade          0.008130  0.667434  0.356967   0.664983     0.762704  0.113621   \n",
       "sqft_above    -0.010842  0.605567  0.477600   0.685342     0.876597  0.183512   \n",
       "sqft_basement -0.005151  0.323816  0.303093   0.283770     0.435043  0.015286   \n",
       "yr_built       0.021380  0.054012  0.154178   0.506019     0.318049  0.053080   \n",
       "yr_renovated  -0.016907  0.126434  0.018841   0.050739     0.055363  0.007644   \n",
       "zipcode       -0.008224 -0.053203 -0.152668  -0.203866    -0.199430 -0.129574   \n",
       "lat           -0.001891  0.307003 -0.008931   0.024573     0.052529 -0.085683   \n",
       "long           0.020799  0.021626  0.129473   0.223042     0.240223  0.229521   \n",
       "sqft_living15 -0.002901  0.585379  0.391638   0.568634     0.756420  0.144608   \n",
       "sqft_lot15    -0.138798  0.082447  0.029244   0.087175     0.183286  0.718557   \n",
       "\n",
       "                 floors  waterfront      view  condition     grade  \\\n",
       "id             0.018525   -0.002721  0.011592  -0.023783  0.008130   \n",
       "price          0.256794    0.266369  0.397293   0.036362  0.667434   \n",
       "bedrooms       0.175429   -0.006582  0.079532   0.028472  0.356967   \n",
       "bathrooms      0.500653    0.063744  0.187737  -0.124982  0.664983   \n",
       "sqft_living    0.353949    0.103818  0.284611  -0.058753  0.762704   \n",
       "sqft_lot      -0.005201    0.021604  0.074710  -0.008958  0.113621   \n",
       "floors         1.000000    0.023698  0.029444  -0.263768  0.458183   \n",
       "waterfront     0.023698    1.000000  0.401857   0.016653  0.082775   \n",
       "view           0.029444    0.401857  1.000000   0.045990  0.251321   \n",
       "condition     -0.263768    0.016653  0.045990   1.000000 -0.144674   \n",
       "grade          0.458183    0.082775  0.251321  -0.144674  1.000000   \n",
       "sqft_above     0.523885    0.072075  0.167649  -0.158214  0.755923   \n",
       "sqft_basement -0.245705    0.080588  0.276947   0.174105  0.168392   \n",
       "yr_built       0.489319   -0.026161 -0.053440  -0.361417  0.446963   \n",
       "yr_renovated   0.006338    0.092885  0.103917  -0.060618  0.014414   \n",
       "zipcode       -0.059121    0.030285  0.084827   0.003026 -0.184862   \n",
       "lat            0.049614   -0.014274  0.006157  -0.014941  0.114084   \n",
       "long           0.125419   -0.041910 -0.078400  -0.106500  0.198372   \n",
       "sqft_living15  0.279885    0.086463  0.280439  -0.092824  0.713202   \n",
       "sqft_lot15    -0.011269    0.030703  0.072575  -0.003406  0.119248   \n",
       "\n",
       "               sqft_above  sqft_basement  yr_built  yr_renovated   zipcode  \\\n",
       "id              -0.010842      -0.005151  0.021380     -0.016907 -0.008224   \n",
       "price            0.605567       0.323816  0.054012      0.126434 -0.053203   \n",
       "bedrooms         0.477600       0.303093  0.154178      0.018841 -0.152668   \n",
       "bathrooms        0.685342       0.283770  0.506019      0.050739 -0.203866   \n",
       "sqft_living      0.876597       0.435043  0.318049      0.055363 -0.199430   \n",
       "sqft_lot         0.183512       0.015286  0.053080      0.007644 -0.129574   \n",
       "floors           0.523885      -0.245705  0.489319      0.006338 -0.059121   \n",
       "waterfront       0.072075       0.080588 -0.026161      0.092885  0.030285   \n",
       "view             0.167649       0.276947 -0.053440      0.103917  0.084827   \n",
       "condition       -0.158214       0.174105 -0.361417     -0.060618  0.003026   \n",
       "grade            0.755923       0.168392  0.446963      0.014414 -0.184862   \n",
       "sqft_above       1.000000      -0.051943  0.423898      0.023285 -0.261190   \n",
       "sqft_basement   -0.051943       1.000000 -0.133124      0.071323  0.074845   \n",
       "yr_built         0.423898      -0.133124  1.000000     -0.224874 -0.346869   \n",
       "yr_renovated     0.023285       0.071323 -0.224874      1.000000  0.064357   \n",
       "zipcode         -0.261190       0.074845 -0.346869      0.064357  1.000000   \n",
       "lat             -0.000816       0.110538 -0.148122      0.029398  0.267048   \n",
       "long             0.343803      -0.144765  0.409356     -0.068372 -0.564072   \n",
       "sqft_living15    0.731870       0.200355  0.326229     -0.002673 -0.279033   \n",
       "sqft_lot15       0.194050       0.017276  0.070958      0.007854 -0.147221   \n",
       "\n",
       "                    lat      long  sqft_living15  sqft_lot15  \n",
       "id            -0.001891  0.020799      -0.002901   -0.138798  \n",
       "price          0.307003  0.021626       0.585379    0.082447  \n",
       "bedrooms      -0.008931  0.129473       0.391638    0.029244  \n",
       "bathrooms      0.024573  0.223042       0.568634    0.087175  \n",
       "sqft_living    0.052529  0.240223       0.756420    0.183286  \n",
       "sqft_lot      -0.085683  0.229521       0.144608    0.718557  \n",
       "floors         0.049614  0.125419       0.279885   -0.011269  \n",
       "waterfront    -0.014274 -0.041910       0.086463    0.030703  \n",
       "view           0.006157 -0.078400       0.280439    0.072575  \n",
       "condition     -0.014941 -0.106500      -0.092824   -0.003406  \n",
       "grade          0.114084  0.198372       0.713202    0.119248  \n",
       "sqft_above    -0.000816  0.343803       0.731870    0.194050  \n",
       "sqft_basement  0.110538 -0.144765       0.200355    0.017276  \n",
       "yr_built      -0.148122  0.409356       0.326229    0.070958  \n",
       "yr_renovated   0.029398 -0.068372      -0.002673    0.007854  \n",
       "zipcode        0.267048 -0.564072      -0.279033   -0.147221  \n",
       "lat            1.000000 -0.135512       0.048858   -0.086419  \n",
       "long          -0.135512  1.000000       0.334605    0.254451  \n",
       "sqft_living15  0.048858  0.334605       1.000000    0.183192  \n",
       "sqft_lot15    -0.086419  0.254451       0.183192    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = house_data.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "555f5779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price            1.000000\n",
       "sqft_living      0.702035\n",
       "grade            0.667434\n",
       "sqft_above       0.605567\n",
       "sqft_living15    0.585379\n",
       "bathrooms        0.525138\n",
       "view             0.397293\n",
       "sqft_basement    0.323816\n",
       "bedrooms         0.308350\n",
       "lat              0.307003\n",
       "waterfront       0.266369\n",
       "floors           0.256794\n",
       "yr_renovated     0.126434\n",
       "sqft_lot         0.089661\n",
       "sqft_lot15       0.082447\n",
       "yr_built         0.054012\n",
       "condition        0.036362\n",
       "long             0.021626\n",
       "id              -0.016762\n",
       "zipcode         -0.053203\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix['price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c89c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = house_data.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbf8c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_data[['sqft_living', 'grade', 'sqft_above', 'bathrooms', 'view', 'sqft_basement', 'bedrooms', 'floors', 'sqft_lot', 'lat', 'long']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "596c3177",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWith all these features we are dealilng with the 'Curse of Dimensionality'\\n\\nBecause our initial selected features have high dimensionality the model will train Very, very slowly. \\nFor most algorithms, adding dimensions has a non-linear impact on processing time, and once you can no longer fit \\nall the data in memory, you should prepare for an exponential increase in processing time.\\n\\nThe common theme of these problems is that when the dimensionality increases, \\nthe volume of the space increases so fast that the available data become sparse. Meaning we need even more data to train.\\nIn order to obtain a reliable result, the amount of data needed often grows exponentially with the dimensionality.\\n\\nAs the dimensionality increases, the distance between objects may be heavily dominated by noise. That is, the distance and similarity \\nbetween two points in a high-dimensional space may not reflect the real relationship between the points.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "With all these features we are dealilng with the 'Curse of Dimensionality'\n",
    "\n",
    "Because our initial selected features have high dimensionality the model will train Very, very slowly. \n",
    "For most algorithms, adding dimensions has a non-linear impact on processing time, and once you can no longer fit \n",
    "all the data in memory, you should prepare for an exponential increase in processing time.\n",
    "\n",
    "The common theme of these problems is that when the dimensionality increases, \n",
    "the volume of the space increases so fast that the available data become sparse. Meaning we need even more data to train.\n",
    "In order to obtain a reliable result, the amount of data needed often grows exponentially with the dimensionality.\n",
    "\n",
    "As the dimensionality increases, the distance between objects may be heavily dominated by noise. That is, the distance and similarity \n",
    "between two points in a high-dimensional space may not reflect the real relationship between the points.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9aa50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_data[['sqft_living', 'grade', 'sqft_above', 'bathrooms']] # minimize dimensionality of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d003f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76656528",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOur target variable has a high range as well\\ntraining and dev loss values, this is entirely dependent on the scale of your target values (how big are your target values?) \\nIf your target values are big and you want smaller train and dev loss values, you can normalise the target values.\\n\\nneural networks are sensitive to a range of both features and targets. Normalizing both features and targets can facilitate learning.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Our target variable has a high range as well\n",
    "training and dev loss values, this is entirely dependent on the scale of your target values (how big are your target values?) \n",
    "If your target values are big and you want smaller train and dev loss values, you can normalise the target values.\n",
    "\n",
    "neural networks are sensitive to a range of both features and targets. Normalizing both features and targets can facilitate learning.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3acec66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6430b4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7700000.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41ba119e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05fb279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_y = []\n",
    "min_y = min(y)\n",
    "max_y = max(y)\n",
    "for i in y:\n",
    "    temp = (i-min_y)/(max_y-min_y)\n",
    "    norm_y.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd18b459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(norm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e5684f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_y_series = pd.Series(norm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e29e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_y = y\n",
    "y = norm_y_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9900895",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c54251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = X.shape[1]\n",
    "OUTPUT_SIZE = 1\n",
    "INITIAL_NODE_SIZE = math.ceil((INPUT_SIZE + OUTPUT_SIZE) * (2/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d39e0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(num_nodes=INITIAL_NODE_SIZE):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_nodes, activation='relu', input_shape=(4,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12bb1fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "541/541 - 2s - loss: 0.0178 - val_loss: 0.0044 - 2s/epoch - 3ms/step\n",
      "Epoch 2/50\n",
      "541/541 - 1s - loss: 0.0034 - val_loss: 0.0023 - 669ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "541/541 - 1s - loss: 0.0021 - val_loss: 0.0016 - 722ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "541/541 - 1s - loss: 0.0015 - val_loss: 0.0013 - 731ms/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "541/541 - 1s - loss: 0.0013 - val_loss: 0.0011 - 647ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0011 - 579ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9078e-04 - 624ms/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.6660e-04 - 594ms/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.5324e-04 - 612ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.9097e-04 - 694ms/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4128e-04 - 692ms/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4682e-04 - 623ms/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4110e-04 - 614ms/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 0.0010 - 747ms/epoch - 1ms/step\n",
      "Epoch 15/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.6938e-04 - 527ms/epoch - 973us/step\n",
      "Epoch 16/50\n",
      "541/541 - 0s - loss: 9.9351e-04 - val_loss: 0.0010 - 493ms/epoch - 911us/step\n",
      "Epoch 17/50\n",
      "541/541 - 1s - loss: 9.8516e-04 - val_loss: 9.4349e-04 - 573ms/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "541/541 - 1s - loss: 9.7544e-04 - val_loss: 9.2624e-04 - 523ms/epoch - 966us/step\n",
      "Epoch 19/50\n",
      "541/541 - 1s - loss: 9.6936e-04 - val_loss: 0.0011 - 530ms/epoch - 980us/step\n",
      "Epoch 20/50\n",
      "541/541 - 1s - loss: 9.7788e-04 - val_loss: 8.9225e-04 - 707ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "541/541 - 1s - loss: 9.6663e-04 - val_loss: 8.9219e-04 - 762ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "541/541 - 1s - loss: 9.6359e-04 - val_loss: 9.0031e-04 - 625ms/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "541/541 - 1s - loss: 9.6633e-04 - val_loss: 8.9913e-04 - 563ms/epoch - 1ms/step\n",
      "Epoch 24/50\n",
      "541/541 - 1s - loss: 9.6398e-04 - val_loss: 9.1174e-04 - 646ms/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "541/541 - 0s - loss: 9.7041e-04 - val_loss: 8.8954e-04 - 497ms/epoch - 919us/step\n",
      "Epoch 26/50\n",
      "541/541 - 1s - loss: 9.6199e-04 - val_loss: 0.0011 - 566ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "541/541 - 1s - loss: 9.7075e-04 - val_loss: 8.9208e-04 - 513ms/epoch - 949us/step\n",
      "Epoch 28/50\n",
      "541/541 - 1s - loss: 9.6097e-04 - val_loss: 9.1669e-04 - 623ms/epoch - 1ms/step\n",
      "Epoch 29/50\n",
      "541/541 - 0s - loss: 9.6911e-04 - val_loss: 8.9863e-04 - 474ms/epoch - 876us/step\n",
      "Epoch 30/50\n",
      "541/541 - 1s - loss: 9.6826e-04 - val_loss: 9.2993e-04 - 561ms/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "541/541 - 1s - loss: 9.6888e-04 - val_loss: 9.3694e-04 - 525ms/epoch - 970us/step\n",
      "Epoch 32/50\n",
      "541/541 - 1s - loss: 9.5941e-04 - val_loss: 8.8833e-04 - 587ms/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "541/541 - 0s - loss: 9.6416e-04 - val_loss: 8.9596e-04 - 469ms/epoch - 867us/step\n",
      "Epoch 34/50\n",
      "541/541 - 0s - loss: 9.6840e-04 - val_loss: 8.9552e-04 - 463ms/epoch - 856us/step\n",
      "Epoch 35/50\n",
      "541/541 - 1s - loss: 9.6455e-04 - val_loss: 9.1947e-04 - 521ms/epoch - 962us/step\n",
      "Epoch 36/50\n",
      "541/541 - 1s - loss: 9.6482e-04 - val_loss: 9.1726e-04 - 536ms/epoch - 991us/step\n",
      "Epoch 37/50\n",
      "541/541 - 0s - loss: 9.6300e-04 - val_loss: 8.9802e-04 - 493ms/epoch - 912us/step\n",
      "Epoch 38/50\n",
      "541/541 - 1s - loss: 9.6513e-04 - val_loss: 9.1084e-04 - 544ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "541/541 - 1s - loss: 9.6340e-04 - val_loss: 9.8190e-04 - 551ms/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "541/541 - 1s - loss: 9.5995e-04 - val_loss: 9.0510e-04 - 551ms/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "541/541 - 1s - loss: 9.5519e-04 - val_loss: 8.8911e-04 - 545ms/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "541/541 - 1s - loss: 9.6346e-04 - val_loss: 9.2890e-04 - 550ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "541/541 - 1s - loss: 9.5620e-04 - val_loss: 9.1463e-04 - 553ms/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "541/541 - 1s - loss: 9.6647e-04 - val_loss: 8.9853e-04 - 545ms/epoch - 1ms/step\n",
      "Epoch 45/50\n",
      "541/541 - 1s - loss: 9.5921e-04 - val_loss: 8.9851e-04 - 508ms/epoch - 939us/step\n",
      "Epoch 46/50\n",
      "541/541 - 1s - loss: 9.6049e-04 - val_loss: 9.4676e-04 - 563ms/epoch - 1ms/step\n",
      "Epoch 47/50\n",
      "541/541 - 1s - loss: 9.6425e-04 - val_loss: 8.9515e-04 - 554ms/epoch - 1ms/step\n",
      "Epoch 48/50\n",
      "541/541 - 1s - loss: 9.6186e-04 - val_loss: 9.8202e-04 - 547ms/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "541/541 - 1s - loss: 9.6677e-04 - val_loss: 8.9273e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 50/50\n",
      "541/541 - 1s - loss: 9.5834e-04 - val_loss: 8.9506e-04 - 544ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model = buildModel()\n",
    "model_4_3_1  = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6107742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Validation Error')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_4_3_1.history['val_loss'])\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Validation Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7350b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-1 with 1 in hidden layer:\n",
      "\n",
      "Epoch 1/50\n",
      "541/541 - 1s - loss: 0.0025 - val_loss: 0.0019 - 882ms/epoch - 2ms/step\n",
      "Epoch 2/50\n",
      "541/541 - 1s - loss: 0.0019 - val_loss: 0.0017 - 579ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "541/541 - 1s - loss: 0.0018 - val_loss: 0.0016 - 660ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "541/541 - 1s - loss: 0.0016 - val_loss: 0.0014 - 524ms/epoch - 969us/step\n",
      "Epoch 5/50\n",
      "541/541 - 1s - loss: 0.0014 - val_loss: 0.0011 - 554ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "541/541 - 1s - loss: 0.0012 - val_loss: 0.0011 - 564ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "541/541 - 1s - loss: 0.0012 - val_loss: 0.0010 - 564ms/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 558ms/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 562ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 559ms/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 562ms/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9585e-04 - 560ms/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9725e-04 - 564ms/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9705e-04 - 512ms/epoch - 946us/step\n",
      "Epoch 15/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9588e-04 - 522ms/epoch - 964us/step\n",
      "Epoch 16/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 565ms/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9669e-04 - 560ms/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 561ms/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9826e-04 - 564ms/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 561ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 566ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9942e-04 - 578ms/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 562ms/epoch - 1ms/step\n",
      "Epoch 24/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 528ms/epoch - 976us/step\n",
      "Epoch 25/50\n",
      "541/541 - 0s - loss: 0.0011 - val_loss: 9.9800e-04 - 488ms/epoch - 901us/step\n",
      "Epoch 26/50\n",
      "541/541 - 0s - loss: 0.0011 - val_loss: 0.0010 - 482ms/epoch - 890us/step\n",
      "Epoch 27/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9821e-04 - 730ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "541/541 - 0s - loss: 0.0011 - val_loss: 9.9715e-04 - 484ms/epoch - 895us/step\n",
      "Epoch 29/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9637e-04 - 535ms/epoch - 988us/step\n",
      "Epoch 30/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 585ms/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9896e-04 - 601ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 593ms/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 559ms/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 773ms/epoch - 1ms/step\n",
      "Epoch 35/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 528ms/epoch - 975us/step\n",
      "Epoch 36/50\n",
      "541/541 - 0s - loss: 0.0011 - val_loss: 0.0010 - 471ms/epoch - 870us/step\n",
      "Epoch 37/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 750ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 667ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 529ms/epoch - 977us/step\n",
      "Epoch 40/50\n",
      "541/541 - 0s - loss: 0.0011 - val_loss: 0.0010 - 497ms/epoch - 918us/step\n",
      "Epoch 41/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9764e-04 - 573ms/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 781ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 577ms/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0011 - 550ms/epoch - 1ms/step\n",
      "Epoch 45/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 688ms/epoch - 1ms/step\n",
      "Epoch 46/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9784e-04 - 649ms/epoch - 1ms/step\n",
      "Epoch 47/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 671ms/epoch - 1ms/step\n",
      "Epoch 48/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9835e-04 - 628ms/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 812ms/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 646ms/epoch - 1ms/step\n",
      "Model-1 fit accuracy: 0.5443967020116598\n",
      "\n",
      "\n",
      "Model-2 with 2 in hidden layer:\n",
      "\n",
      "Epoch 1/50\n",
      "541/541 - 1s - loss: 0.0378 - val_loss: 0.0104 - 951ms/epoch - 2ms/step\n",
      "Epoch 2/50\n",
      "541/541 - 1s - loss: 0.0068 - val_loss: 0.0041 - 519ms/epoch - 959us/step\n",
      "Epoch 3/50\n",
      "541/541 - 1s - loss: 0.0033 - val_loss: 0.0025 - 559ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "541/541 - 1s - loss: 0.0022 - val_loss: 0.0018 - 559ms/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "541/541 - 1s - loss: 0.0017 - val_loss: 0.0015 - 606ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "541/541 - 1s - loss: 0.0015 - val_loss: 0.0013 - 515ms/epoch - 953us/step\n",
      "Epoch 7/50\n",
      "541/541 - 1s - loss: 0.0013 - val_loss: 0.0011 - 527ms/epoch - 974us/step\n",
      "Epoch 8/50\n",
      "541/541 - 1s - loss: 0.0012 - val_loss: 0.0011 - 515ms/epoch - 951us/step\n",
      "Epoch 9/50\n",
      "541/541 - 0s - loss: 0.0011 - val_loss: 0.0010 - 491ms/epoch - 907us/step\n",
      "Epoch 10/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 515ms/epoch - 951us/step\n",
      "Epoch 11/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9715e-04 - 557ms/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.7517e-04 - 504ms/epoch - 932us/step\n",
      "Epoch 13/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.5231e-04 - 508ms/epoch - 939us/step\n",
      "Epoch 14/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4784e-04 - 514ms/epoch - 950us/step\n",
      "Epoch 15/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4136e-04 - 562ms/epoch - 1ms/step\n",
      "Epoch 16/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3483e-04 - 561ms/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3529e-04 - 576ms/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3102e-04 - 672ms/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3325e-04 - 560ms/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3407e-04 - 562ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.2969e-04 - 558ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4314e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3155e-04 - 510ms/epoch - 942us/step\n",
      "Epoch 24/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4404e-04 - 559ms/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 0.0011 - 572ms/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3541e-04 - 566ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3425e-04 - 560ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3027e-04 - 555ms/epoch - 1ms/step\n",
      "Epoch 29/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3082e-04 - 554ms/epoch - 1ms/step\n",
      "Epoch 30/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3159e-04 - 555ms/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4194e-04 - 556ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3132e-04 - 556ms/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3822e-04 - 564ms/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.5399e-04 - 523ms/epoch - 966us/step\n",
      "Epoch 35/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.9499e-04 - 516ms/epoch - 953us/step\n",
      "Epoch 36/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4752e-04 - 555ms/epoch - 1ms/step\n",
      "Epoch 37/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.5527e-04 - 567ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4570e-04 - 560ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3250e-04 - 562ms/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4504e-04 - 558ms/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3399e-04 - 557ms/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.5790e-04 - 559ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.5761e-04 - 556ms/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3636e-04 - 557ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.5461e-04 - 566ms/epoch - 1ms/step\n",
      "Epoch 46/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3254e-04 - 560ms/epoch - 1ms/step\n",
      "Epoch 47/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3251e-04 - 511ms/epoch - 944us/step\n",
      "Epoch 48/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3433e-04 - 551ms/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.6376e-04 - 554ms/epoch - 1ms/step\n",
      "Epoch 50/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3747e-04 - 553ms/epoch - 1ms/step\n",
      "Model-2 fit accuracy: 0.5753731059900096\n",
      "\n",
      "\n",
      "Model-3 with 3 in hidden layer:\n",
      "\n",
      "Epoch 1/50\n",
      "541/541 - 1s - loss: 0.2993 - val_loss: 0.0847 - 874ms/epoch - 2ms/step\n",
      "Epoch 2/50\n",
      "541/541 - 1s - loss: 0.0461 - val_loss: 0.0206 - 546ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "541/541 - 1s - loss: 0.0124 - val_loss: 0.0065 - 549ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "541/541 - 1s - loss: 0.0047 - val_loss: 0.0032 - 551ms/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "541/541 - 1s - loss: 0.0027 - val_loss: 0.0022 - 546ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "541/541 - 1s - loss: 0.0021 - val_loss: 0.0018 - 546ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "541/541 - 1s - loss: 0.0018 - val_loss: 0.0016 - 546ms/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "541/541 - 1s - loss: 0.0016 - val_loss: 0.0015 - 548ms/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "541/541 - 1s - loss: 0.0015 - val_loss: 0.0014 - 554ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "541/541 - 1s - loss: 0.0015 - val_loss: 0.0013 - 547ms/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "541/541 - 1s - loss: 0.0014 - val_loss: 0.0013 - 532ms/epoch - 983us/step\n",
      "Epoch 12/50\n",
      "541/541 - 1s - loss: 0.0013 - val_loss: 0.0012 - 561ms/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "541/541 - 1s - loss: 0.0013 - val_loss: 0.0012 - 561ms/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "541/541 - 1s - loss: 0.0012 - val_loss: 0.0011 - 539ms/epoch - 996us/step\n",
      "Epoch 15/50\n",
      "541/541 - 1s - loss: 0.0012 - val_loss: 0.0011 - 564ms/epoch - 1ms/step\n",
      "Epoch 16/50\n",
      "541/541 - 1s - loss: 0.0012 - val_loss: 0.0011 - 560ms/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 546ms/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "541/541 - 0s - loss: 0.0011 - val_loss: 0.0010 - 498ms/epoch - 921us/step\n",
      "Epoch 19/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9365e-04 - 539ms/epoch - 997us/step\n",
      "Epoch 20/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.7244e-04 - 553ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.6021e-04 - 547ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.5550e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4669e-04 - 548ms/epoch - 1ms/step\n",
      "Epoch 24/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4321e-04 - 550ms/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.9742e-04 - 551ms/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3606e-04 - 550ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3391e-04 - 550ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.6631e-04 - 560ms/epoch - 1ms/step\n",
      "Epoch 29/50\n",
      "541/541 - 1s - loss: 9.9930e-04 - val_loss: 9.4305e-04 - 520ms/epoch - 962us/step\n",
      "Epoch 30/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3828e-04 - 557ms/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "541/541 - 1s - loss: 9.9945e-04 - val_loss: 9.2521e-04 - 552ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "541/541 - 1s - loss: 9.9077e-04 - val_loss: 9.1906e-04 - 552ms/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "541/541 - 1s - loss: 9.8287e-04 - val_loss: 9.5116e-04 - 558ms/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "541/541 - 1s - loss: 9.8692e-04 - val_loss: 9.3666e-04 - 558ms/epoch - 1ms/step\n",
      "Epoch 35/50\n",
      "541/541 - 1s - loss: 9.7411e-04 - val_loss: 9.3279e-04 - 562ms/epoch - 1ms/step\n",
      "Epoch 36/50\n",
      "541/541 - 1s - loss: 9.7497e-04 - val_loss: 9.3359e-04 - 556ms/epoch - 1ms/step\n",
      "Epoch 37/50\n",
      "541/541 - 1s - loss: 9.7624e-04 - val_loss: 8.8943e-04 - 559ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "541/541 - 1s - loss: 9.6805e-04 - val_loss: 9.0463e-04 - 561ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "541/541 - 1s - loss: 9.6806e-04 - val_loss: 8.9100e-04 - 555ms/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "541/541 - 1s - loss: 9.6414e-04 - val_loss: 8.8394e-04 - 557ms/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "541/541 - 1s - loss: 9.6281e-04 - val_loss: 8.8523e-04 - 550ms/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "541/541 - 1s - loss: 9.5392e-04 - val_loss: 8.8844e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "541/541 - 1s - loss: 9.5812e-04 - val_loss: 9.3130e-04 - 562ms/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "541/541 - 1s - loss: 9.6238e-04 - val_loss: 8.8191e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 45/50\n",
      "541/541 - 1s - loss: 9.5851e-04 - val_loss: 8.8154e-04 - 545ms/epoch - 1ms/step\n",
      "Epoch 46/50\n",
      "541/541 - 1s - loss: 9.6428e-04 - val_loss: 8.8607e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 47/50\n",
      "541/541 - 1s - loss: 9.5267e-04 - val_loss: 8.8344e-04 - 540ms/epoch - 998us/step\n",
      "Epoch 48/50\n",
      "541/541 - 1s - loss: 9.5555e-04 - val_loss: 8.7530e-04 - 529ms/epoch - 978us/step\n",
      "Epoch 49/50\n",
      "541/541 - 1s - loss: 9.5584e-04 - val_loss: 8.8461e-04 - 520ms/epoch - 962us/step\n",
      "Epoch 50/50\n",
      "541/541 - 0s - loss: 9.5109e-04 - val_loss: 8.7494e-04 - 495ms/epoch - 915us/step\n",
      "Model-3 fit accuracy: 0.6036983184445496\n",
      "\n",
      "\n",
      "Model-4 with 4 in hidden layer:\n",
      "\n",
      "Epoch 1/50\n",
      "541/541 - 1s - loss: 0.1923 - val_loss: 0.0421 - 847ms/epoch - 2ms/step\n",
      "Epoch 2/50\n",
      "541/541 - 1s - loss: 0.0229 - val_loss: 0.0124 - 512ms/epoch - 946us/step\n",
      "Epoch 3/50\n",
      "541/541 - 1s - loss: 0.0078 - val_loss: 0.0049 - 503ms/epoch - 929us/step\n",
      "Epoch 4/50\n",
      "541/541 - 1s - loss: 0.0036 - val_loss: 0.0027 - 508ms/epoch - 939us/step\n",
      "Epoch 5/50\n",
      "541/541 - 1s - loss: 0.0023 - val_loss: 0.0020 - 554ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "541/541 - 1s - loss: 0.0018 - val_loss: 0.0017 - 564ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "541/541 - 1s - loss: 0.0016 - val_loss: 0.0015 - 553ms/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "541/541 - 1s - loss: 0.0014 - val_loss: 0.0014 - 555ms/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "541/541 - 1s - loss: 0.0013 - val_loss: 0.0012 - 555ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "541/541 - 1s - loss: 0.0013 - val_loss: 0.0012 - 549ms/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "541/541 - 1s - loss: 0.0013 - val_loss: 0.0012 - 549ms/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "541/541 - 1s - loss: 0.0012 - val_loss: 0.0011 - 513ms/epoch - 948us/step\n",
      "Epoch 13/50\n",
      "541/541 - 1s - loss: 0.0012 - val_loss: 0.0012 - 520ms/epoch - 962us/step\n",
      "Epoch 14/50\n",
      "541/541 - 1s - loss: 0.0012 - val_loss: 0.0011 - 556ms/epoch - 1ms/step\n",
      "Epoch 15/50\n",
      "541/541 - 0s - loss: 0.0012 - val_loss: 0.0011 - 497ms/epoch - 919us/step\n",
      "Epoch 16/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 511ms/epoch - 944us/step\n",
      "Epoch 17/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0013 - 553ms/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0011 - 551ms/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.8781e-04 - 552ms/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.9229e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.7079e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 549ms/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0020 - 551ms/epoch - 1ms/step\n",
      "Epoch 24/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 557ms/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.9086e-04 - 548ms/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 665ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.5245e-04 - 510ms/epoch - 942us/step\n",
      "Epoch 28/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.5530e-04 - 561ms/epoch - 1ms/step\n",
      "Epoch 29/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3169e-04 - 558ms/epoch - 1ms/step\n",
      "Epoch 30/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.3822e-04 - 558ms/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.7267e-04 - 550ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.5474e-04 - 561ms/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "541/541 - 0s - loss: 0.0010 - val_loss: 9.6142e-04 - 474ms/epoch - 876us/step\n",
      "Epoch 34/50\n",
      "541/541 - 0s - loss: 0.0010 - val_loss: 9.8848e-04 - 499ms/epoch - 923us/step\n",
      "Epoch 35/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.4478e-04 - 511ms/epoch - 945us/step\n",
      "Epoch 36/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 0.0010 - 552ms/epoch - 1ms/step\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.2219e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.2303e-04 - 551ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 0.0011 - 549ms/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.2051e-04 - 570ms/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "541/541 - 0s - loss: 9.8794e-04 - val_loss: 9.1591e-04 - 471ms/epoch - 871us/step\n",
      "Epoch 42/50\n",
      "541/541 - 1s - loss: 9.9417e-04 - val_loss: 8.9013e-04 - 548ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "541/541 - 1s - loss: 9.9477e-04 - val_loss: 9.5981e-04 - 502ms/epoch - 928us/step\n",
      "Epoch 44/50\n",
      "541/541 - 1s - loss: 9.9132e-04 - val_loss: 9.4000e-04 - 535ms/epoch - 989us/step\n",
      "Epoch 45/50\n",
      "541/541 - 1s - loss: 9.9312e-04 - val_loss: 8.9253e-04 - 555ms/epoch - 1ms/step\n",
      "Epoch 46/50\n",
      "541/541 - 1s - loss: 9.9617e-04 - val_loss: 9.5865e-04 - 556ms/epoch - 1ms/step\n",
      "Epoch 47/50\n",
      "541/541 - 1s - loss: 9.9543e-04 - val_loss: 8.9035e-04 - 552ms/epoch - 1ms/step\n",
      "Epoch 48/50\n",
      "541/541 - 1s - loss: 9.9422e-04 - val_loss: 8.9124e-04 - 563ms/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "541/541 - 1s - loss: 9.9269e-04 - val_loss: 9.2632e-04 - 554ms/epoch - 1ms/step\n",
      "Epoch 50/50\n",
      "541/541 - 1s - loss: 9.7928e-04 - val_loss: 0.0011 - 553ms/epoch - 1ms/step\n",
      "Model-4 fit accuracy: 0.5199797662307758\n",
      "\n",
      "\n",
      "Model-5 with 5 in hidden layer:\n",
      "\n",
      "Epoch 1/50\n",
      "541/541 - 1s - loss: 0.0788 - val_loss: 0.0094 - 874ms/epoch - 2ms/step\n",
      "Epoch 2/50\n",
      "541/541 - 1s - loss: 0.0070 - val_loss: 0.0053 - 560ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "541/541 - 1s - loss: 0.0042 - val_loss: 0.0033 - 558ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "541/541 - 1s - loss: 0.0028 - val_loss: 0.0023 - 558ms/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "541/541 - 1s - loss: 0.0021 - val_loss: 0.0018 - 553ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "541/541 - 1s - loss: 0.0017 - val_loss: 0.0015 - 560ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "541/541 - 1s - loss: 0.0015 - val_loss: 0.0013 - 559ms/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "541/541 - 1s - loss: 0.0013 - val_loss: 0.0011 - 563ms/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 0.0010 - 551ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "541/541 - 1s - loss: 0.0011 - val_loss: 9.6977e-04 - 521ms/epoch - 964us/step\n",
      "Epoch 11/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.5083e-04 - 548ms/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.2921e-04 - 550ms/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.6396e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.3088e-04 - 512ms/epoch - 945us/step\n",
      "Epoch 15/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.2195e-04 - 513ms/epoch - 948us/step\n",
      "Epoch 16/50\n",
      "541/541 - 1s - loss: 9.9837e-04 - val_loss: 9.3133e-04 - 550ms/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "541/541 - 1s - loss: 9.9624e-04 - val_loss: 9.4056e-04 - 554ms/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.8184e-04 - 553ms/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "541/541 - 1s - loss: 9.9900e-04 - val_loss: 9.3884e-04 - 553ms/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "541/541 - 1s - loss: 9.9849e-04 - val_loss: 9.6337e-04 - 552ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.2959e-04 - 551ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "541/541 - 1s - loss: 9.9426e-04 - val_loss: 9.4492e-04 - 554ms/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.5711e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 24/50\n",
      "541/541 - 1s - loss: 9.9270e-04 - val_loss: 9.2835e-04 - 547ms/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "541/541 - 1s - loss: 9.9532e-04 - val_loss: 9.3701e-04 - 551ms/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.1963e-04 - 552ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "541/541 - 1s - loss: 9.9920e-04 - val_loss: 9.2391e-04 - 548ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "541/541 - 1s - loss: 9.9350e-04 - val_loss: 9.3566e-04 - 550ms/epoch - 1ms/step\n",
      "Epoch 29/50\n",
      "541/541 - 1s - loss: 9.8728e-04 - val_loss: 9.1501e-04 - 547ms/epoch - 1ms/step\n",
      "Epoch 30/50\n",
      "541/541 - 1s - loss: 9.9255e-04 - val_loss: 9.2986e-04 - 546ms/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "541/541 - 1s - loss: 9.9656e-04 - val_loss: 9.4096e-04 - 545ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "541/541 - 1s - loss: 9.9506e-04 - val_loss: 9.1323e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "541/541 - 1s - loss: 9.9231e-04 - val_loss: 9.2670e-04 - 547ms/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "541/541 - 1s - loss: 9.9108e-04 - val_loss: 9.2790e-04 - 557ms/epoch - 1ms/step\n",
      "Epoch 35/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.2794e-04 - 547ms/epoch - 1ms/step\n",
      "Epoch 36/50\n",
      "541/541 - 1s - loss: 9.8975e-04 - val_loss: 0.0013 - 576ms/epoch - 1ms/step\n",
      "Epoch 37/50\n",
      "541/541 - 1s - loss: 0.0010 - val_loss: 9.1755e-04 - 517ms/epoch - 955us/step\n",
      "Epoch 38/50\n",
      "541/541 - 1s - loss: 9.9021e-04 - val_loss: 9.3409e-04 - 513ms/epoch - 948us/step\n",
      "Epoch 39/50\n",
      "541/541 - 1s - loss: 9.9244e-04 - val_loss: 9.1284e-04 - 514ms/epoch - 950us/step\n",
      "Epoch 40/50\n",
      "541/541 - 1s - loss: 9.8446e-04 - val_loss: 9.3131e-04 - 517ms/epoch - 956us/step\n",
      "Epoch 41/50\n",
      "541/541 - 1s - loss: 9.8817e-04 - val_loss: 9.3558e-04 - 551ms/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "541/541 - 1s - loss: 9.8664e-04 - val_loss: 9.3570e-04 - 551ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "541/541 - 1s - loss: 9.8080e-04 - val_loss: 9.1903e-04 - 552ms/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "541/541 - 1s - loss: 9.9276e-04 - val_loss: 9.4875e-04 - 553ms/epoch - 1ms/step\n",
      "Epoch 45/50\n",
      "541/541 - 1s - loss: 9.8953e-04 - val_loss: 9.1771e-04 - 551ms/epoch - 1ms/step\n",
      "Epoch 46/50\n",
      "541/541 - 1s - loss: 9.8526e-04 - val_loss: 9.2293e-04 - 558ms/epoch - 1ms/step\n",
      "Epoch 47/50\n",
      "541/541 - 1s - loss: 9.8570e-04 - val_loss: 9.5413e-04 - 553ms/epoch - 1ms/step\n",
      "Epoch 48/50\n",
      "541/541 - 1s - loss: 9.7276e-04 - val_loss: 9.3453e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "541/541 - 1s - loss: 9.9225e-04 - val_loss: 9.3115e-04 - 549ms/epoch - 1ms/step\n",
      "Epoch 50/50\n",
      "541/541 - 1s - loss: 9.8750e-04 - val_loss: 9.8050e-04 - 541ms/epoch - 999us/step\n",
      "Model-5 fit accuracy: 0.5558836273488217\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's try evaluating models with varying size of the hidden layer\n",
    "from sklearn.metrics import r2_score\n",
    "SIZE_MULTIPLIER = [0.25, 0.5, 0.75, 1, 1.25]\n",
    "MODELS = []\n",
    "R2_SCORES = []\n",
    "\n",
    "for i, mp in enumerate(SIZE_MULTIPLIER):\n",
    "    numNodes = math.ceil(int(INITIAL_NODE_SIZE * mp))\n",
    "    model = buildModel(numNodes)\n",
    "    print(f\"Model-{i+1} with {numNodes} in hidden layer:\\n\")\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=2)\n",
    "    MODELS.append(model)\n",
    "    # note: here we should have set aside another portion of our train-test-split for unseen test data, but since our original dataset is fairly small, we'll stick with using the validation data to evaluate predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    fit_acc = r2_score(y_test, y_pred)\n",
    "    R2_SCORES.append(fit_acc)\n",
    "    print(f\"Model-{i+1} fit accuracy: {fit_acc}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b30864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this outcome, this rule of thumb seems to be debunked, but these models can improve with other techniques such as hyperparamater tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
